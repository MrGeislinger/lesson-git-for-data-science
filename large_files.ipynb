{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#But-Why?!\" data-toc-modified-id=\"But-Why?!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>But Why?!</a></span><ul class=\"toc-item\"><li><span><a href=\"#GitHub-no-like\" data-toc-modified-id=\"GitHub-no-like-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>GitHub no like</a></span></li><li><span><a href=\"#Bloated-repos\" data-toc-modified-id=\"Bloated-repos-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Bloated repos</a></span></li></ul></li><li><span><a href=\"#Solutions...?\" data-toc-modified-id=\"Solutions...?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Solutions...?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Remove-the-data\" data-toc-modified-id=\"Remove-the-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Remove the data</a></span></li><li><span><a href=\"#Keep-it-with-the-workaround-Git-LFS\" data-toc-modified-id=\"Keep-it-with-the-workaround-Git-LFS-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Keep it with the workaround Git LFS</a></span></li><li><span><a href=\"#GitHub-Releases\" data-toc-modified-id=\"GitHub-Releases-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>GitHub Releases</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large files in your repo can be no fun ðŸ™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But Why?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub no like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and most obviously is that GitHub has a limit on size of individual files (100 MB): https://docs.github.com/en/free-pro-team@latest/github/managing-large-files/what-is-my-disk-quota\n",
    "\n",
    "> Note: In the past, GitHub had a hard limit to a single repo of 100GB but that doesn't seem to be present as of October 2020. But hey, don't make your repo 100 GB large. Come on, you're better than that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloated repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more subtle, but if you have large files in your repo they get meshed into how your repo works. And if you change any details of your data, it will keep a (compressed) _copy_ of your changes. This means slow syncing and annoyances when you clone somewhere else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if you have some breaking commit because of some large data, you should probably remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's actually a great [article](https://medium.com/analytics-vidhya/tutorial-removing-large-files-from-git-78dbf4cf83a) from one of the Flatiron instructors Erinn Hoffman on this. She goes into detail about removing the commit and the large data associated with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But even after removing the data, you should still figure out how to make it accessible for anyone using your repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep it with the workaround Git LFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Git Large File Storage (or Git LFS)](https://git-lfs.github.com/) is a nice workaround that organizations like GitHub have developed for dealing with larger files.\n",
    "\n",
    "Essentially, it's cheating by storing a \"pointer\" file in your repo that \"points\" to the real large file which is stored separately from your repo (remote). Then you can get the data when you're actually using it in a commit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally, it's fine but it's really not optimized for data science and machine learning work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub Releases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [GitHub Releases](https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/releasing-projects-on-github) has been my favorite method so far for large data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
